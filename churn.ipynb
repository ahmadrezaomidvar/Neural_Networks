{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset details includes bank's customers data. Our aim is to predict if the customer will continue working with the bank or will left it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "import datetime\n",
    "import dataframe_image as dfi\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv('./Dataset/Churn_Modelling.csv.xls', index_col='RowNumber')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df as image\n",
    "dfi.export(df.head(10), 'churntable.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CustomerId','Surname'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(prefix='Geo', data=df, columns=['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df_dummies.replace(to_replace={'Gender': {'Female': 1,'Male':0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_encoded.Exited ,data=df_encoded)\n",
    "plt.ylabel(\"Count of each Target class\")\n",
    "plt.xlabel(\"Target classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.hist(figsize=(15,12),bins = 15)\n",
    "plt.title(\"Features Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMtrx = df_encoded.corr()\n",
    "mask = np.zeros_like(corrMtrx)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(15, 15))\n",
    "plt.title('Feature Correlation')\n",
    "\n",
    "cmap = sns.diverging_palette(260, 10, n=10, as_cmap=True)\n",
    "sns.heatmap(corrMtrx, mask=mask, vmax=1.2, cmap=cmap, ax=axs, annot=True, fmt='0.2g', linewidths=1, square=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.plot(kind='box', subplots=True, layout=(8,4), sharex=False, sharey=False, fontsize=12, figsize=(15,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4, figsize=(30, 40))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.15)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, col in enumerate(df_encoded.columns[:]):\n",
    "    sns.boxplot(x=df_encoded.Exited, y=df_encoded[col], ax=axs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(20, 8))\n",
    "sns.boxplot(data=df_encoded.iloc[:,:], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(['Exited'],axis=1)\n",
    "y = df_encoded.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(20, 8))\n",
    "g = sns.boxplot(data=X_train, ax=ax,)\n",
    "g.set_xticklabels(df_encoded.columns[:-1], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(20, 8))\n",
    "g = sns.boxplot(data=X_test, ax=ax)\n",
    "g.set_xticklabels(df_encoded.columns[:-1], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(f'Logistic Regression Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Cross Entropy model loss: {log_loss(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_train_pca.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(X_train_pca[:, :1][y_train == 0], X_train_pca[:, 1:2][y_train == 0], 'bo', label='0', alpha=0.7, markeredgecolor='k')\n",
    "plt.plot(X_train_pca[:, :1][y_train == 1], X_train_pca[:, 1:2][y_train == 1], 'ro', label='1', alpha=0.7, markeredgecolor='k')\n",
    "\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second principal component')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "X_train_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(X_train_lda[:, 0][y_train == 0], [0 for _ in range(X_train_lda[:, 0][y_train == 0].shape[0])], 'bo', label='0', alpha=0.7, markeredgecolor='k')\n",
    "plt.plot(X_train_lda[:, 0][y_train == 1], [0 for _ in range(X_train_lda[:, 0][y_train == 1].shape[0])], 'ro', label='1', alpha=0.7, markeredgecolor='k')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = lda.score(X_train, y_train)\n",
    "test_acc = lda.score(X_test, y_test)\n",
    "print(f'Train accuracy: {train_acc:.2f}, Test accuracy: {test_acc:.2f}')\n",
    "# calculate loss of lda\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "y_pred = lda.predict_proba(X_test)\n",
    "print(f'Log loss: {log_loss(y_test, y_pred):.2f}')\n",
    "y_pred = lda.predict(X_test)\n",
    "print(f'MSE: {mean_squared_error(y_test, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "train_acc = qda.score(X_train, y_train)\n",
    "test_acc = qda.score(X_test, y_test)\n",
    "print(f'Train accuracy: {train_acc:.2f}, Test accuracy: {test_acc :.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(num_neurons:list, learning_rate:float):\n",
    "\n",
    "    model = Sequential()\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    model.add(Dense(units = num_neurons[0], kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
    "\n",
    "    # Adding the hidden layers\n",
    "    for i in range(1, len(num_neurons)):\n",
    "        # model.add(Dense(units = num_neurons[i], kernel_initializer = 'uniform', activation = 'relu'))\n",
    "        model.add(Dense(units = num_neurons[i], kernel_initializer = 'uniform', activation = 'relu', kernel_regularizer=l2(0.01)))\n",
    "        # model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    # Model Summary\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# Fitting the ANN to the Training set\n",
    "# model = Model([5, 5], 0.001)\n",
    "model = Model([20, 20, 10, 6], 0.001)\n",
    "# model = Model([20, 40, 60, 80, 60, 40, 20], 0.001)\n",
    "history = model.fit(X_train, y_train, batch_size = 10, epochs = 1, verbose = 1, \n",
    "                    validation_data=(X_test, y_test), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "score, acc = model.evaluate(X_train, y_train,\n",
    "                            batch_size=10)\n",
    "print(f'Train score: {score: .3f}')\n",
    "print(f'Train accuracy: {acc: .3f}')\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "print('-----'*20)\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=10)\n",
    "print(f'Test score: {score: .3f}')\n",
    "print(f'Test accuracy: {acc: .3f}')\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e55e2bf7dd4ea1433edd1eeb22ab1a4d8784211bbea2c4b51d02507569900b38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
