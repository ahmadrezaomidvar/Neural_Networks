# Neural_Networks
Artificial Neural Networks Strengths and Weaknesses
MATH4069 Statistical Machine Learning Group project report - 2022/2023

## Abstract
Artificial Neural Networks (ANN) are a class of Machine Learning algorithms that attempt to imitate the function of neurons in the biological brain. Taking input data through a system of interconnected nodes with different weightings for each input and neuron. This process can produce simple results from complex input data. ANNs have flexibility to be applied to different complex issues, such as Facial Recognition, Medical Diagnosis and Automated Trading Strategies. In this report we discuss the history and development of neural networks, the mathematics that underpin their operation, the application of neural networks to toy and real-world data as well as the strengths and weaknesses of neural networks as a machine learning algorithm. In this report we tested the performance of a multi-layer feed forward neural network against PCA and LDA on a toy dataset; performing a classification task and found that due to the toy datasets small size, the neural network was unable to perform better than the traditional machine learning algorithms. However, when applied to the real-world data which contained 10,000 data points and 10 features, our neural network was able to surpass PCA.

## Contents
1. Introduction
2. History of Neural Networks
   
   2.1 Humble Beginnings

   2.2 Hebbian Learning

   2.3 A Glimpse Into the Future: How Rosenblatt ‘solved AI’

   2.4 Stanford’s Love for Acronyms

   2.5 The End of An Era: AI ”Winters” 

   2.6 Resurrection: The AI Spring of the 2010s

3. Network Description and Visualisation
   
   3.1 Description

   3.2 Visualisation

4. Mathematics behind Neural Networks
   
   4.1 Single Layer Neural Networks

   4.2 Activation Functions

   4.3 Loss Functions

   4.4 Back Propagation

   4.5 Gradient Descent

   4.6 Feature Scaling

5. Application
   
    5.1 Toy Data
    
    5.2 Bank Customer Data
    
    5.3 Feature Scaling
    
    5.4 Classification with PCA
    
    5.5 Classification with Neural Networks

6. Issues in Training
   
    6.1 Initialisation
    
    6.2 Over-fitting and Hyperparameter Tuning

7. Conclusions


## Contributors
Ahmadreza Omidvar,
Joshua Ranson,
Jakub Niekrasz